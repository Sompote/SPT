{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OwCt4jbSG00pT9kvBiSjAciALv3chW9N",
      "authorship_tag": "ABX9TyOffeEOzjVKvGj3aM1fn9vc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sompote/SPT/blob/main/SPT__predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDHjwBi-5q_w"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/RIC/SPT.xlsx')\n",
        "data=np.array(df)\n",
        "X=data[:,0:2]\n",
        "y=data[:,2]\n",
        "y=np.reshape(y,(X.shape[0],1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "et-6G2S7bI8E",
        "outputId": "ea349b3b-9c4c-4b63-b111-946266d21dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     s1   N     state\n",
              "0    50   2  0.070462\n",
              "1   100   3  0.102345\n",
              "2   100   4  0.058772\n",
              "3   200   7  0.074251\n",
              "4   300  10  0.100299\n",
              "5   400  14  0.107165\n",
              "6    50   5 -0.038817\n",
              "7   100   6 -0.006930\n",
              "8   200  10  0.009668\n",
              "9   300  12  0.034051\n",
              "10  400  16  0.038629\n",
              "11   50   8 -0.109256\n",
              "12  100  11 -0.065521\n",
              "13  100  11 -0.070583\n",
              "14  200  13 -0.046961\n",
              "15  300  17 -0.023694\n",
              "16  400  19 -0.011245"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e572b56-be76-469b-b312-ccce1d49764e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s1</th>\n",
              "      <th>N</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0.070462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>0.102345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200</td>\n",
              "      <td>7</td>\n",
              "      <td>0.074251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>10</td>\n",
              "      <td>0.100299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>400</td>\n",
              "      <td>14</td>\n",
              "      <td>0.107165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.038817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.006930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.009668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>300</td>\n",
              "      <td>12</td>\n",
              "      <td>0.034051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>400</td>\n",
              "      <td>16</td>\n",
              "      <td>0.038629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>50</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.109256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.065521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.070583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>200</td>\n",
              "      <td>13</td>\n",
              "      <td>-0.046961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>300</td>\n",
              "      <td>17</td>\n",
              "      <td>-0.023694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>400</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.011245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e572b56-be76-469b-b312-ccce1d49764e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e572b56-be76-469b-b312-ccce1d49764e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e572b56-be76-469b-b312-ccce1d49764e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8rSjjYO_zTp",
        "outputId": "0f12fc85-68d5-43bd-a943-a0e05cffc5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07046233,  0.10234465,  0.05877166,  0.07425114,  0.10029862,\n",
              "        0.10716516, -0.03881704, -0.00693019,  0.00966791,  0.0340507 ,\n",
              "        0.03862928, -0.10925634, -0.0655215 , -0.0705835 , -0.04696137,\n",
              "       -0.02369362, -0.01124502])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fIOJOzO_910",
        "outputId": "0a4b392f-42e9-4bb5-a933-8d3abd1b9e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIS_wngkAP9Q",
        "outputId": "6a8e0b91-c9fd-46db-83bf-febd48bb9376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3.,   2.,   8.,   9.,   5.,   5.,  50.],\n",
              "       [  3.,   2.,   8.,   9.,   3.,   5., 100.],\n",
              "       [  3.,   2.,   8.,   9.,   6.,   5., 150.],\n",
              "       [  3.,   2.,   8.,   9.,   3.,   5., 200.],\n",
              "       [  3.,   2.,   8.,   9.,   2.,   5., 250.],\n",
              "       [  3.,   2.,   8.,   9.,   2.,   5., 300.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ATDmPKAp3e",
        "outputId": "a5c426db-c4b2-4077-acfd-cb8a2304893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.,  4.,  5.,  7., 10.],\n",
              "       [ 6.,  8.,  9.,  1.,  6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "sc = MinMaxScaler()\n",
        "sc_y=MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "y_train=sc_y.fit_transform(y_train)\n",
        "y_test=sc_y.transform(y_test)\n",
        "\n",
        "# Define neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=20, epochs=500, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.evaluate(X_train, y_train)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "def mape(actual, pred):\n",
        "  return np.mean(np.abs((actual - pred) / actual)) * 100\n",
        "mape_cal=mape(y_test, y_pred)\n",
        "print('mape =',mape_cal)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual values\")\n",
        "plt.ylabel(\"Predicted values\")\n",
        "plt.title(\"Deep neural network regression\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ITJj-u7-8JY4",
        "outputId": "0492d9f3-f504-4278-85a7-b5b2f31128f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2984 - val_loss: 720.9495\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.2752 - val_loss: 1118.7499\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.2511 - val_loss: 1621.0186\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2277 - val_loss: 2237.2656\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2055 - val_loss: 2954.1841\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.1849 - val_loss: 3763.6499\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1662 - val_loss: 4669.4790\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1496 - val_loss: 5717.0391\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1347 - val_loss: 6885.7852\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1216 - val_loss: 8174.4707\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1097 - val_loss: 9571.4131\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0994 - val_loss: 11080.9199\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0907 - val_loss: 12700.7832\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0837 - val_loss: 14449.3252\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0781 - val_loss: 16271.6191\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0742 - val_loss: 18214.5508\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0719 - val_loss: 20179.3281\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0710 - val_loss: 22128.3711\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0711 - val_loss: 23967.5898\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0720 - val_loss: 25597.2129\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0731 - val_loss: 26955.4297\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0737 - val_loss: 28007.4648\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0734 - val_loss: 28756.5020\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0722 - val_loss: 29222.8164\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0701 - val_loss: 29441.7637\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0674 - val_loss: 29456.5156\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0642 - val_loss: 29312.3340\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0609 - val_loss: 29071.3477\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0578 - val_loss: 28791.6719\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0549 - val_loss: 28493.3770\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0525 - val_loss: 28233.9062\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0502 - val_loss: 28034.1523\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0481 - val_loss: 27919.2715\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0463 - val_loss: 27918.1777\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0447 - val_loss: 28037.2539\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0432 - val_loss: 28288.6777\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0416 - val_loss: 28675.1797\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0399 - val_loss: 29213.6895\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0382 - val_loss: 29892.3301\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0365 - val_loss: 30695.0547\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0346 - val_loss: 31613.8750\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0328 - val_loss: 32630.9844\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0310 - val_loss: 33720.1914\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0293 - val_loss: 34856.9648\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0277 - val_loss: 36022.5469\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0262 - val_loss: 37196.5938\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0248 - val_loss: 38358.8672\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0235 - val_loss: 39484.7227\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0222 - val_loss: 40559.7812\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0209 - val_loss: 41573.3984\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0197 - val_loss: 42518.6250\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0185 - val_loss: 43391.1797\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0172 - val_loss: 44171.6016\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0160 - val_loss: 44882.3828\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0149 - val_loss: 45562.3867\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0138 - val_loss: 46231.0508\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0129 - val_loss: 46912.3555\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0120 - val_loss: 47622.3203\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0111 - val_loss: 48374.3672\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0103 - val_loss: 49176.6172\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0096 - val_loss: 50031.1836\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0089 - val_loss: 50933.5664\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0082 - val_loss: 51873.6328\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - val_loss: 52835.8164\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - val_loss: 53800.6914\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 54747.3008\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - val_loss: 55654.1367\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - val_loss: 56503.6914\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 57282.0938\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 57982.3477\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0049 - val_loss: 58605.0156\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 59158.2188\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 59666.8516\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 60135.1680\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 60578.0977\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 60988.9141\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - val_loss: 61387.1172\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 61793.3164\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 62227.7070\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 62706.7734\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 63238.0664\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 63820.9688\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 64433.2344\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 65061.9570\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 65692.9453\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 66312.8125\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - val_loss: 66911.0000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 67480.4375\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - val_loss: 68018.3125\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 68527.3359\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 69012.7422\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 69481.6094\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 69927.2422\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 70359.7812\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 70790.5234\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 71227.3281\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 71676.7188\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 72142.9297\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 72624.1641\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 73115.2344\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 73605.2344\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 74090.1484\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 74557.2188\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 74996.7812\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 75401.6328\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 75769.1641\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 76101.6641\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 76401.9844\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 76676.0000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 76930.8125\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 77172.2969\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 77407.5078\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 77640.0703\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - val_loss: 77871.2266\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 78099.3984\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 78320.5391\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 78531.1016\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 78728.9531\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 78912.2188\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 79079.6641\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 79231.1406\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 79368.8984\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 79496.1484\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 79616.8281\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 79734.0625\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 79849.7891\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 79966.4141\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 80086.2188\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 80209.1562\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 80329.4531\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 80449.5156\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 80564.3750\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 80673.6094\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 80777.1875\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 80873.0000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 80959.6250\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 81036.5391\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 81104.3125\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 81165.5547\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 81224.0312\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 81282.9844\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 81343.8828\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 81406.5000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 81468.9453\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 81528.5859\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 81582.4531\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 81628.9609\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 81668.6875\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - val_loss: 81703.1719\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - val_loss: 81734.5312\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 81765.3828\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 81798.5000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 81835.6562\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 81877.1875\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - val_loss: 81921.8750\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 81967.9844\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 82012.8672\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - val_loss: 82053.7812\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 82088.3672\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - val_loss: 82115.3438\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - val_loss: 82136.6484\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - val_loss: 82155.0078\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 82169.2422\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 82181.0391\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0014 - val_loss: 82191.4141\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - val_loss: 82200.7188\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 82208.4141\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - val_loss: 82217.0000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - val_loss: 82226.7266\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0014 - val_loss: 82237.6250\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - val_loss: 82249.1641\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 82260.0156\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 82268.9922\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - val_loss: 82275.7266\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0014 - val_loss: 82280.1797\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 82282.4219\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 82279.3984\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - val_loss: 82272.2031\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0014 - val_loss: 82261.7734\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0014 - val_loss: 82252.0156\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 82244.3125\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 82241.0859\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - val_loss: 82243.6875\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - val_loss: 82251.6406\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 82259.4297\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0013 - val_loss: 82264.5391\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - val_loss: 82265.2188\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0013 - val_loss: 82263.8281\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - val_loss: 82260.1172\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 82254.6484\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 82247.2656\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 82236.8594\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 82222.9531\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 82207.7031\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0013 - val_loss: 82194.2188\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - val_loss: 82185.0781\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - val_loss: 82180.7969\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - val_loss: 82181.5547\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - val_loss: 82186.3281\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0013 - val_loss: 82192.4375\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 82198.1016\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 82200.0547\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 82197.7344\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 82194.8906\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - val_loss: 82190.8125\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - val_loss: 82184.5938\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 82178.9375\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - val_loss: 82174.2422\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 82171.4297\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 82170.1797\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0012 - val_loss: 82166.2422\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 82163.7812\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 82163.0859\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 82163.9141\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0012 - val_loss: 82166.8359\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 82170.8359\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 82174.8516\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 82176.9141\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 82177.8906\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 82180.4766\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 82184.2109\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 82188.9531\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 82196.6875\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 82208.5156\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 82223.2031\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 82238.1484\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 82251.4531\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 82259.0234\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 82261.6016\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 82263.0234\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 82264.0625\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 82265.2188\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 82266.0859\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 82266.9922\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 82268.2031\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 82269.0312\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 82270.4844\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 82275.6250\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 82286.1875\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 82299.4844\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 82314.6172\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 82328.8672\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 82342.2500\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 82353.1641\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 82361.0469\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 82365.8125\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 82368.0078\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 82368.7109\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 82371.3750\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 82377.9688\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 82388.5000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 82400.7031\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 82412.9922\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 82423.3906\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 82430.8516\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 82436.3359\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 82443.5703\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 82455.9609\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 82472.6875\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 82491.1641\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 82508.2812\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 82523.0000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 82535.4453\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 82545.0000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 82552.9922\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 82561.5625\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - val_loss: 82571.0781\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 82580.1875\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 82588.6484\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 82597.9141\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 82608.8984\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 82621.7734\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.9747e-04 - val_loss: 82636.8594\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.9386e-04 - val_loss: 82654.3672\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.9008e-04 - val_loss: 82673.0156\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.8676e-04 - val_loss: 82690.6875\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.8276e-04 - val_loss: 82707.3125\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.7915e-04 - val_loss: 82724.1172\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.7548e-04 - val_loss: 82740.5547\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.7201e-04 - val_loss: 82755.9844\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 9.6831e-04 - val_loss: 82770.6484\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.6468e-04 - val_loss: 82784.7109\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.6108e-04 - val_loss: 82798.2031\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.5754e-04 - val_loss: 82812.3359\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.5421e-04 - val_loss: 82825.5469\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.5054e-04 - val_loss: 82837.9453\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.4711e-04 - val_loss: 82850.1172\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 9.4399e-04 - val_loss: 82862.1172\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.4065e-04 - val_loss: 82877.5781\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.3737e-04 - val_loss: 82896.5156\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 9.3408e-04 - val_loss: 82918.0469\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.3072e-04 - val_loss: 82938.5703\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.2732e-04 - val_loss: 82955.2344\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 9.2410e-04 - val_loss: 82965.0000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9.2112e-04 - val_loss: 82970.1172\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.1763e-04 - val_loss: 82976.3672\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.1457e-04 - val_loss: 82986.5547\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.1145e-04 - val_loss: 83001.3438\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.0829e-04 - val_loss: 83019.5859\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.0494e-04 - val_loss: 83037.8750\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.0195e-04 - val_loss: 83055.7422\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.9859e-04 - val_loss: 83074.7812\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.9575e-04 - val_loss: 83095.0938\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.9276e-04 - val_loss: 83115.7031\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.8973e-04 - val_loss: 83135.9141\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.8659e-04 - val_loss: 83153.9141\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8.8365e-04 - val_loss: 83167.4141\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.8045e-04 - val_loss: 83180.7656\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.7772e-04 - val_loss: 83197.2578\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.7471e-04 - val_loss: 83218.4766\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.7167e-04 - val_loss: 83243.3438\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.6876e-04 - val_loss: 83270.0859\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.6613e-04 - val_loss: 83295.5625\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.6289e-04 - val_loss: 83318.2109\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.6010e-04 - val_loss: 83339.7891\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.5742e-04 - val_loss: 83360.7891\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.5441e-04 - val_loss: 83381.9844\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.5152e-04 - val_loss: 83404.4375\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.4869e-04 - val_loss: 83427.0781\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.4582e-04 - val_loss: 83447.3594\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.4349e-04 - val_loss: 83464.3672\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.4029e-04 - val_loss: 83480.4219\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.3768e-04 - val_loss: 83495.8203\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.3505e-04 - val_loss: 83512.9375\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.3243e-04 - val_loss: 83531.5938\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.2966e-04 - val_loss: 83553.0547\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.2708e-04 - val_loss: 83578.5078\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.2446e-04 - val_loss: 83606.6875\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.2177e-04 - val_loss: 83633.8672\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.1899e-04 - val_loss: 83657.1797\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.1584e-04 - val_loss: 83677.4766\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.1303e-04 - val_loss: 83698.4062\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.1014e-04 - val_loss: 83719.4688\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.0702e-04 - val_loss: 83739.4922\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.0400e-04 - val_loss: 83759.0391\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.0092e-04 - val_loss: 83776.8984\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9777e-04 - val_loss: 83794.5312\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.9475e-04 - val_loss: 83809.6875\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.9174e-04 - val_loss: 83823.8281\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.8892e-04 - val_loss: 83841.5000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.8590e-04 - val_loss: 83862.7969\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.8481e-04 - val_loss: 83879.7656\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.8217e-04 - val_loss: 83901.1016\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.7831e-04 - val_loss: 83937.4062\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.7749e-04 - val_loss: 84001.5156\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.7577e-04 - val_loss: 84090.3125\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.7345e-04 - val_loss: 84187.5391\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.7061e-04 - val_loss: 84274.1172\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.6831e-04 - val_loss: 84334.2188\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.6588e-04 - val_loss: 84363.0156\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.6445e-04 - val_loss: 84369.7812\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.6250e-04 - val_loss: 84368.1172\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.6013e-04 - val_loss: 84369.4766\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.5872e-04 - val_loss: 84382.9375\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 7.5745e-04 - val_loss: 84411.4844\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.5546e-04 - val_loss: 84450.4609\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.5303e-04 - val_loss: 84490.9375\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.5159e-04 - val_loss: 84526.9141\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.5017e-04 - val_loss: 84555.0547\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4852e-04 - val_loss: 84576.3984\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4711e-04 - val_loss: 84599.1953\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4575e-04 - val_loss: 84627.3906\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.4462e-04 - val_loss: 84656.0312\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4340e-04 - val_loss: 84697.0703\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4237e-04 - val_loss: 84749.2031\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4028e-04 - val_loss: 84805.0000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.3940e-04 - val_loss: 84847.6484\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.3808e-04 - val_loss: 84878.6328\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.3659e-04 - val_loss: 84900.6875\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.3531e-04 - val_loss: 84919.4688\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.3387e-04 - val_loss: 84940.8359\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.3220e-04 - val_loss: 84965.4375\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.3144e-04 - val_loss: 84991.0625\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.2990e-04 - val_loss: 85017.1484\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.2847e-04 - val_loss: 85045.6172\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.2740e-04 - val_loss: 85072.5000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.2624e-04 - val_loss: 85097.3125\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.2498e-04 - val_loss: 85116.2500\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.2378e-04 - val_loss: 85129.7812\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.2244e-04 - val_loss: 85140.1484\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2114e-04 - val_loss: 85150.8125\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.2044e-04 - val_loss: 85163.2109\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.2025e-04 - val_loss: 85176.4922\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.1891e-04 - val_loss: 85185.7578\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.1763e-04 - val_loss: 85205.9141\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.1672e-04 - val_loss: 85240.5000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.1597e-04 - val_loss: 85286.7266\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.1503e-04 - val_loss: 85335.2031\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.1439e-04 - val_loss: 85376.3438\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.1344e-04 - val_loss: 85402.4453\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.1240e-04 - val_loss: 85412.7266\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.1154e-04 - val_loss: 85410.9609\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.1045e-04 - val_loss: 85407.1016\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.0966e-04 - val_loss: 85409.9219\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.0886e-04 - val_loss: 85423.4609\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.0796e-04 - val_loss: 85446.0625\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.0739e-04 - val_loss: 85466.8125\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0608e-04 - val_loss: 85494.7500\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.0575e-04 - val_loss: 85531.5000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.0454e-04 - val_loss: 85574.0547\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0368e-04 - val_loss: 85612.7812\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.0325e-04 - val_loss: 85638.5781\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.0242e-04 - val_loss: 85651.2734\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.0174e-04 - val_loss: 85656.5312\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.0099e-04 - val_loss: 85663.0078\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.9993e-04 - val_loss: 85674.5625\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9870e-04 - val_loss: 85691.0000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.9810e-04 - val_loss: 85709.6328\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.9746e-04 - val_loss: 85730.9531\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.9654e-04 - val_loss: 85753.5703\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.9536e-04 - val_loss: 85775.8906\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.9486e-04 - val_loss: 85800.4297\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.9422e-04 - val_loss: 85824.7344\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.9337e-04 - val_loss: 85843.8672\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.9267e-04 - val_loss: 85854.6172\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.9174e-04 - val_loss: 85858.9844\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.9097e-04 - val_loss: 85861.1875\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.8977e-04 - val_loss: 85869.5234\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.8957e-04 - val_loss: 85891.1719\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8831e-04 - val_loss: 85925.0859\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.8761e-04 - val_loss: 85962.3906\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8801e-04 - val_loss: 85988.6328\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.8644e-04 - val_loss: 86007.2734\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.8539e-04 - val_loss: 86033.9297\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.8496e-04 - val_loss: 86077.8750\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.8446e-04 - val_loss: 86137.9062\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8317e-04 - val_loss: 86200.6953\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 6.8230e-04 - val_loss: 86250.8750\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6.8245e-04 - val_loss: 86281.8906\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 6.8160e-04 - val_loss: 86297.0859\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 6.8043e-04 - val_loss: 86303.0703\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.7971e-04 - val_loss: 86307.4922\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 6.7961e-04 - val_loss: 86319.8984\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 6.7691e-04 - val_loss: 86340.6328\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.7065e-04 - val_loss: 86361.3516\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.6457e-04 - val_loss: 86367.9766\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 6.5939e-04 - val_loss: 86369.0781\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.6067e-04 - val_loss: 86664.6328\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.6066e-04 - val_loss: 86785.0703\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.5761e-04 - val_loss: 86752.1172\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6.5269e-04 - val_loss: 86654.0625\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 6.4702e-04 - val_loss: 86584.3438\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 6.4369e-04 - val_loss: 86672.6641\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 6.4264e-04 - val_loss: 86839.2500\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.4121e-04 - val_loss: 87126.8359\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.3879e-04 - val_loss: 87517.3672\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.3477e-04 - val_loss: 87966.4219\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.3294e-04 - val_loss: 88301.7422\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.3132e-04 - val_loss: 88535.9062\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.3047e-04 - val_loss: 88693.0938\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 6.2923e-04 - val_loss: 88791.9141\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 6.2695e-04 - val_loss: 88836.6562\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 6.2478e-04 - val_loss: 88819.3047\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.2202e-04 - val_loss: 88726.9375\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1949e-04 - val_loss: 88558.4766\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1735e-04 - val_loss: 88499.1484\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 6.1661e-04 - val_loss: 88538.9844\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1493e-04 - val_loss: 88660.6484\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 6.1262e-04 - val_loss: 88848.4219\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 6.1128e-04 - val_loss: 88900.9844\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 6.1013e-04 - val_loss: 88825.3125\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 6.0877e-04 - val_loss: 88645.2422\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.0692e-04 - val_loss: 88545.4688\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.0568e-04 - val_loss: 88513.4219\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.0464e-04 - val_loss: 88517.7734\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.0334e-04 - val_loss: 88543.2656\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.0206e-04 - val_loss: 88576.8438\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.0109e-04 - val_loss: 88609.9609\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.0037e-04 - val_loss: 88470.1875\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.9934e-04 - val_loss: 88358.6797\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.9840e-04 - val_loss: 88277.0625\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.9754e-04 - val_loss: 88220.9062\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.9648e-04 - val_loss: 88188.3750\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.9534e-04 - val_loss: 88175.6250\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.9424e-04 - val_loss: 88186.5391\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 5.9334e-04 - val_loss: 88217.9375\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.9233e-04 - val_loss: 88260.3359\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.9114e-04 - val_loss: 88317.3125\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.9043e-04 - val_loss: 88237.1641\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.8953e-04 - val_loss: 88058.0703\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 5.8878e-04 - val_loss: 87933.2109\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.8776e-04 - val_loss: 87871.5469\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.8710e-04 - val_loss: 87856.3438\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.8669e-04 - val_loss: 87874.4531\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.8550e-04 - val_loss: 87909.7969\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 5.8475e-04 - val_loss: 87962.5234\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.8377e-04 - val_loss: 88024.9141\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 5.8302e-04 - val_loss: 88083.4766\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.8228e-04 - val_loss: 88006.4375\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 5.8121e-04 - val_loss: 87940.5156\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.8067e-04 - val_loss: 87902.6953\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.7988e-04 - val_loss: 87888.6641\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 5.7896e-04 - val_loss: 87892.7578\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 5.7798e-04 - val_loss: 87900.6641\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 5.7788e-04 - val_loss: 87902.7500\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 5.7687e-04 - val_loss: 87900.7891\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.7619e-04 - val_loss: 87909.5234\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.7501e-04 - val_loss: 87940.0547\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.7436e-04 - val_loss: 87997.5938\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7379e-04 - val_loss: 88072.7656\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 88072.7656\n",
            "Mean squared error: 88072.765625\n",
            "mape = 923790.5093601391\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ea289970de42>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Plot results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actual values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2862\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2863\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump\n",
        "# save the scaler\n",
        "dump(sc, open('scaler_x.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "8NvIsvESBbVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1H9Z10cB3Yk",
        "outputId": "0cd9cba8-62f6-4694-f4ac-c34c1ac155ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        ],\n",
              "       [0.39535222],\n",
              "       [0.        ],\n",
              "       [0.28784095],\n",
              "       [0.54950294],\n",
              "       [0.17869223],\n",
              "       [0.77639236],\n",
              "       [0.66216637],\n",
              "       [0.45287238],\n",
              "       [0.96827238],\n",
              "       [0.47280954],\n",
              "       [0.68332222],\n",
              "       [0.20208177],\n",
              "       [0.84791705],\n",
              "       [0.32547275]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "from sklearn.model_selection import KFold\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "sc = MinMaxScaler()\n",
        "sc_y=MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "y_train=sc_y.fit_transform(y_train)\n",
        "y_test=sc_y.transform(y_test)\n",
        "def mape(actual, pred):\n",
        "  return np.mean(np.abs((actual - pred) / actual)) * 100\n",
        "\n",
        "# Define neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(10000, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(5000, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "k = 8 # number of folds kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "mse_list = []\n",
        "mape_list = []\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "  X_train_fold, X_test_fold = X_train[train_index],X_train[test_index]\n",
        "  y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  model.fit(X_train_fold, y_train_fold, batch_size=5, epochs=500,verbose=0)\n",
        "  y_pred_fold = model.predict(X_test_fold)\n",
        "  mse_fold = model.evaluate(X_test_fold, y_test_fold)\n",
        "  mape_fold = mape(y_test_fold, y_pred_fold)\n",
        "  mse_list.append(mse_fold)\n",
        "  mape_list.append(mape_fold)\n",
        "  print('mean absolute percentage error:', mape_fold)\n",
        "mse_avg = np.mean(mse_list)\n",
        "mape_avg = np.mean(mape_list)\n",
        "print('Average mean squared error:', mse_avg)\n",
        "print('Average mean absolute percentage error:', mape_avg)\n",
        "'''\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=20, epochs=500, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.evaluate(X_test, y_test)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "def mape(actual, pred):\n",
        "  return np.mean(np.abs((actual - pred) / actual)) * 100\n",
        "mape_cal=mape(y_test, y_pred)\n",
        "print('mape =',mape_cal)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual values\")\n",
        "plt.ylabel(\"Predicted values\")\n",
        "plt.title(\"Deep neural network regression\")\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "YzDxSxAtCnj9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "b821f0dd-6a7d-475e-cff1-d5275a2970f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0087\n",
            "mean absolute percentage error: 11.09624097902911\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0071\n",
            "mean absolute percentage error: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-61c3db02ca7d>:11: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return np.mean(np.abs((actual - pred) / actual)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033\n",
            "mean absolute percentage error: 9.306364101891454\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0071\n",
            "mean absolute percentage error: 24.06953354231031\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0019\n",
            "mean absolute percentage error: 3.3384307737033323\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.8346e-04\n",
            "mean absolute percentage error: 11.573809464471152\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.5486e-04\n",
            "mean absolute percentage error: 12.76387018435419\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9840e-05\n",
            "mean absolute percentage error: 1.167947779131365\n",
            "Average mean squared error: 0.003668512657213796\n",
            "Average mean absolute percentage error: inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Train model\\nhistory = model.fit(X_train, y_train, batch_size=20, epochs=500, validation_data=(X_test, y_test))\\n\\n# Evaluate model\\ny_pred = model.predict(X_test)\\nmse = model.evaluate(X_test, y_test)\\nprint(\"Mean squared error:\", mse)\\n\\ndef mape(actual, pred):\\n  return np.mean(np.abs((actual - pred) / actual)) * 100\\nmape_cal=mape(y_test, y_pred)\\nprint(\\'mape =\\',mape_cal)\\n\\n# Plot results\\nplt.scatter(y_test, y_pred)\\nplt.xlabel(\"Actual values\")\\nplt.ylabel(\"Predicted values\")\\nplt.title(\"Deep neural network regression\")\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot and save your model\n",
        "import tensorflow as tf\n",
        "img_file = 'model.png'\n",
        "tf.keras.utils.plot_model(model, to_file=img_file, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "VwArrNwjz4ej",
        "outputId": "5abe00aa-8191-4294-d8f1-edefda60eada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byE7AJRdjz_j",
        "outputId": "3254d6ce-19e4-4baf-ae8f-2d9a26a1820b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 100)               300       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 5)                 255       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,611\n",
            "Trainable params: 5,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_fold = model.predict(X_test_fold)\n",
        "mse_fold = model.evaluate(X_test_fold, y_test_fold)\n",
        "mape_fold = mape(y_test_fold, y_pred_fold)\n",
        "mse_list.append(mse_fold)\n",
        "mape_list.append(mape_fold)\n",
        "print('mean absolute percentage error:', mape_fold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3mvu8cY3GeH",
        "outputId": "21af3d94-a4df-4e87-f0b0-bf263ace3534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0039\n",
            "mean absolute percentage error: 9.200652340540183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_test_fold, y_pred_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf34C1ZDTOwF",
        "outputId": "44c3d4a1-a013-4b83-d3ec-0ceb772d0f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.43126723863782"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train=X\n",
        "y_train=y\n",
        "X_test=X_train\n",
        "y_test=y_train\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "sc_y=MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "y_train=sc_y.fit_transform(y_train)\n",
        "y_test=sc_y.transform(y_test)\n",
        "\n",
        "# Define neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=5, epochs=500, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.evaluate(X_train, y_train)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "def mape(actual, pred):\n",
        "  return np.mean(np.abs((actual - pred) / actual)) * 100\n",
        "y_test[y_test == 0] = 0.1\n",
        "mape_cal=mape(y_test, y_pred)\n",
        "print('mape =',mape_cal)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual values\")\n",
        "plt.ylabel(\"Predicted values\")\n",
        "plt.title(\"Deep neural network regression\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "05v0sLzFTVig",
        "outputId": "6d9f37ca-9980-441f-8120-e87edddc7444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 2s 53ms/step - loss: 0.4080 - val_loss: 0.4049\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4033 - val_loss: 0.4004\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3990 - val_loss: 0.3960\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3950 - val_loss: 0.3912\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3895 - val_loss: 0.3841\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3806 - val_loss: 0.3715\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3662 - val_loss: 0.3536\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3428 - val_loss: 0.3033\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2846 - val_loss: 0.2378\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2176 - val_loss: 0.1800\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1687 - val_loss: 0.1370\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1296 - val_loss: 0.1140\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1124 - val_loss: 0.1060\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1036 - val_loss: 0.0971\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0933 - val_loss: 0.0861\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0849 - val_loss: 0.0805\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0783 - val_loss: 0.0704\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0667 - val_loss: 0.0603\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0588 - val_loss: 0.0538\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0513 - val_loss: 0.0452\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0430 - val_loss: 0.0379\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0359 - val_loss: 0.0309\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0292 - val_loss: 0.0250\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0199\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0165\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0129\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0102\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0083\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0062\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0060\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0054\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.0055\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0054 - val_loss: 0.0046\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0045\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0052\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.0044\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.0043\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0042 - val_loss: 0.0039\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0037\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0035\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0035\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0032\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0030\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0030\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0029\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0029\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0028\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0039 - val_loss: 0.0037\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0036 - val_loss: 0.0029\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0029\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0039\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0025\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 142/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 143/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 144/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 145/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 146/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 147/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 148/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 149/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 150/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 151/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 152/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 153/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 154/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 155/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 156/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 157/500\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 158/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 159/500\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 160/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 161/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 162/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 163/500\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 164/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 165/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 166/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 167/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 168/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 169/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 170/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 171/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 172/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 173/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 174/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 175/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0012\n",
            "Epoch 176/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 177/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 178/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 179/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 180/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 181/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 182/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 183/500\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 184/500\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 185/500\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 186/500\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 187/500\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 8.7352e-04 - val_loss: 0.0017\n",
            "Epoch 188/500\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 189/500\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 190/500\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.0010\n",
            "Epoch 191/500\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 192/500\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 193/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0010\n",
            "Epoch 194/500\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 195/500\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 196/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 197/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0012 - val_loss: 9.8798e-04\n",
            "Epoch 198/500\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 9.5785e-04\n",
            "Epoch 199/500\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0010 - val_loss: 9.8067e-04\n",
            "Epoch 200/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 9.5646e-04\n",
            "Epoch 201/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 9.2898e-04\n",
            "Epoch 202/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 203/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 9.6773e-04\n",
            "Epoch 204/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 205/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0010\n",
            "Epoch 206/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 207/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 208/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 9.0386e-04\n",
            "Epoch 209/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 210/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 211/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 212/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 213/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 9.9851e-04\n",
            "Epoch 214/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 9.6540e-04 - val_loss: 8.8401e-04\n",
            "Epoch 215/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.1357e-04 - val_loss: 8.8197e-04\n",
            "Epoch 216/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.8340e-04 - val_loss: 8.4170e-04\n",
            "Epoch 217/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.3549e-04 - val_loss: 8.8007e-04\n",
            "Epoch 218/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.0428e-04 - val_loss: 0.0011\n",
            "Epoch 219/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 8.4827e-04\n",
            "Epoch 220/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 9.8457e-04\n",
            "Epoch 221/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 222/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 8.0659e-04 - val_loss: 0.0014\n",
            "Epoch 223/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0011\n",
            "Epoch 224/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 225/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.8773e-04 - val_loss: 0.0011\n",
            "Epoch 226/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 8.4853e-04\n",
            "Epoch 227/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 228/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 8.6394e-04\n",
            "Epoch 229/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.9609e-04 - val_loss: 9.0658e-04\n",
            "Epoch 230/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 9.1252e-04 - val_loss: 7.6313e-04\n",
            "Epoch 231/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.8774e-04 - val_loss: 7.8788e-04\n",
            "Epoch 232/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.1534e-04 - val_loss: 7.5396e-04\n",
            "Epoch 233/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.6079e-04 - val_loss: 7.3100e-04\n",
            "Epoch 234/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.4472e-04 - val_loss: 0.0013\n",
            "Epoch 235/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 7.5403e-04\n",
            "Epoch 236/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.4910e-04 - val_loss: 0.0011\n",
            "Epoch 237/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 7.4752e-04\n",
            "Epoch 238/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.8046e-04 - val_loss: 7.2389e-04\n",
            "Epoch 239/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.7931e-04 - val_loss: 7.9435e-04\n",
            "Epoch 240/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.0442e-04 - val_loss: 6.9267e-04\n",
            "Epoch 241/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.5343e-04 - val_loss: 8.4464e-04\n",
            "Epoch 242/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.5210e-04 - val_loss: 6.7366e-04\n",
            "Epoch 243/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.2069e-04 - val_loss: 9.6648e-04\n",
            "Epoch 244/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 6.7406e-04\n",
            "Epoch 245/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.7796e-04 - val_loss: 9.0373e-04\n",
            "Epoch 246/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.9058e-04 - val_loss: 7.5708e-04\n",
            "Epoch 247/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.9678e-04 - val_loss: 8.6444e-04\n",
            "Epoch 248/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.2056e-04 - val_loss: 6.6861e-04\n",
            "Epoch 249/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.0838e-04 - val_loss: 6.3057e-04\n",
            "Epoch 250/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 9.2345e-04 - val_loss: 8.2833e-04\n",
            "Epoch 251/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.2566e-04 - val_loss: 7.0312e-04\n",
            "Epoch 252/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 253/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 9.4365e-04 - val_loss: 8.2763e-04\n",
            "Epoch 254/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.5339e-04 - val_loss: 6.2828e-04\n",
            "Epoch 255/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.1514e-04 - val_loss: 7.4186e-04\n",
            "Epoch 256/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.3957e-04 - val_loss: 6.1531e-04\n",
            "Epoch 257/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.9397e-04 - val_loss: 6.7104e-04\n",
            "Epoch 258/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.7018e-04 - val_loss: 6.5096e-04\n",
            "Epoch 259/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.0062e-04 - val_loss: 6.4276e-04\n",
            "Epoch 260/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 8.9277e-04 - val_loss: 6.0327e-04\n",
            "Epoch 261/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 8.8456e-04 - val_loss: 0.0011\n",
            "Epoch 262/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.8591e-04 - val_loss: 6.8388e-04\n",
            "Epoch 263/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.5222e-04 - val_loss: 6.1538e-04\n",
            "Epoch 264/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.1004e-04 - val_loss: 7.9653e-04\n",
            "Epoch 265/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.8594e-04 - val_loss: 5.7962e-04\n",
            "Epoch 266/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.5560e-04 - val_loss: 0.0010\n",
            "Epoch 267/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 9.6567e-04 - val_loss: 5.5865e-04\n",
            "Epoch 268/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.6025e-04 - val_loss: 6.9440e-04\n",
            "Epoch 269/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.4494e-04 - val_loss: 5.7067e-04\n",
            "Epoch 270/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.9378e-04 - val_loss: 5.9065e-04\n",
            "Epoch 271/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.2625e-04 - val_loss: 5.4958e-04\n",
            "Epoch 272/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 6.4435e-04 - val_loss: 9.4550e-04\n",
            "Epoch 273/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.9645e-04 - val_loss: 5.6472e-04\n",
            "Epoch 274/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.9731e-04 - val_loss: 5.5173e-04\n",
            "Epoch 275/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.7572e-04 - val_loss: 5.5256e-04\n",
            "Epoch 276/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 6.8679e-04 - val_loss: 5.2339e-04\n",
            "Epoch 277/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.4850e-04 - val_loss: 6.1712e-04\n",
            "Epoch 278/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.7202e-04 - val_loss: 5.3339e-04\n",
            "Epoch 279/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.5081e-04 - val_loss: 5.2023e-04\n",
            "Epoch 280/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.5218e-04 - val_loss: 5.3377e-04\n",
            "Epoch 281/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.5720e-04 - val_loss: 5.5369e-04\n",
            "Epoch 282/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.1907e-04 - val_loss: 8.5270e-04\n",
            "Epoch 283/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 7.1834e-04 - val_loss: 6.8927e-04\n",
            "Epoch 284/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.3734e-04 - val_loss: 5.9486e-04\n",
            "Epoch 285/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 7.0736e-04 - val_loss: 8.1080e-04\n",
            "Epoch 286/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.7906e-04 - val_loss: 5.2392e-04\n",
            "Epoch 287/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.2339e-04 - val_loss: 5.1807e-04\n",
            "Epoch 288/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.6052e-04 - val_loss: 5.3657e-04\n",
            "Epoch 289/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2864e-04 - val_loss: 9.2576e-04\n",
            "Epoch 290/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.2939e-04 - val_loss: 4.9698e-04\n",
            "Epoch 291/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.1249e-04 - val_loss: 5.0116e-04\n",
            "Epoch 292/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.3333e-04 - val_loss: 4.9283e-04\n",
            "Epoch 293/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.9602e-04 - val_loss: 4.8439e-04\n",
            "Epoch 294/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.8480e-04 - val_loss: 4.7290e-04\n",
            "Epoch 295/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.1533e-04 - val_loss: 4.7485e-04\n",
            "Epoch 296/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.0151e-04 - val_loss: 4.7589e-04\n",
            "Epoch 297/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9121e-04 - val_loss: 4.7612e-04\n",
            "Epoch 298/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.0584e-04 - val_loss: 4.6286e-04\n",
            "Epoch 299/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.7247e-04 - val_loss: 4.6054e-04\n",
            "Epoch 300/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.4036e-04 - val_loss: 5.6346e-04\n",
            "Epoch 301/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.4908e-04 - val_loss: 4.9238e-04\n",
            "Epoch 302/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.2483e-04 - val_loss: 4.6029e-04\n",
            "Epoch 303/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.6338e-04 - val_loss: 4.8359e-04\n",
            "Epoch 304/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.0463e-04 - val_loss: 4.5510e-04\n",
            "Epoch 305/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.8699e-04 - val_loss: 4.5175e-04\n",
            "Epoch 306/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.1522e-04 - val_loss: 4.4412e-04\n",
            "Epoch 307/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.3388e-04 - val_loss: 4.7037e-04\n",
            "Epoch 308/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.2525e-04 - val_loss: 6.0714e-04\n",
            "Epoch 309/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 4.6957e-04\n",
            "Epoch 310/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 311/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.6707e-04 - val_loss: 8.6485e-04\n",
            "Epoch 312/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 5.4952e-04\n",
            "Epoch 313/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.4792e-04 - val_loss: 7.3676e-04\n",
            "Epoch 314/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.5663e-04 - val_loss: 4.3737e-04\n",
            "Epoch 315/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.4872e-04 - val_loss: 6.9557e-04\n",
            "Epoch 316/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.7372e-04 - val_loss: 4.9100e-04\n",
            "Epoch 317/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.5249e-04 - val_loss: 4.4466e-04\n",
            "Epoch 318/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.7406e-04 - val_loss: 5.2034e-04\n",
            "Epoch 319/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.9440e-04 - val_loss: 4.5098e-04\n",
            "Epoch 320/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.5310e-04 - val_loss: 5.8433e-04\n",
            "Epoch 321/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.2678e-04 - val_loss: 6.1378e-04\n",
            "Epoch 322/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.5815e-04 - val_loss: 4.6225e-04\n",
            "Epoch 323/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.6639e-04 - val_loss: 7.9086e-04\n",
            "Epoch 324/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 8.0483e-04 - val_loss: 4.4441e-04\n",
            "Epoch 325/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.2274e-04 - val_loss: 4.3824e-04\n",
            "Epoch 326/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.0984e-04 - val_loss: 4.6119e-04\n",
            "Epoch 327/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6910e-04 - val_loss: 4.1631e-04\n",
            "Epoch 328/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.6386e-04 - val_loss: 4.1203e-04\n",
            "Epoch 329/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.8328e-04 - val_loss: 7.7442e-04\n",
            "Epoch 330/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.3490e-04 - val_loss: 4.5936e-04\n",
            "Epoch 331/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.2166e-04 - val_loss: 4.1362e-04\n",
            "Epoch 332/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.6237e-04 - val_loss: 4.0637e-04\n",
            "Epoch 333/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9338e-04 - val_loss: 4.0188e-04\n",
            "Epoch 334/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.5922e-04 - val_loss: 4.0167e-04\n",
            "Epoch 335/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.9538e-04 - val_loss: 4.0290e-04\n",
            "Epoch 336/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.1453e-04 - val_loss: 3.8634e-04\n",
            "Epoch 337/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.7744e-04 - val_loss: 4.5731e-04\n",
            "Epoch 338/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.4210e-04 - val_loss: 5.3542e-04\n",
            "Epoch 339/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.3189e-04 - val_loss: 4.6838e-04\n",
            "Epoch 340/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.1701e-04 - val_loss: 4.1143e-04\n",
            "Epoch 341/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.9532e-04 - val_loss: 6.1141e-04\n",
            "Epoch 342/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.0731e-04 - val_loss: 4.6971e-04\n",
            "Epoch 343/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 6.1367e-04 - val_loss: 4.4152e-04\n",
            "Epoch 344/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.4544e-04 - val_loss: 5.9174e-04\n",
            "Epoch 345/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.5141e-04 - val_loss: 4.4336e-04\n",
            "Epoch 346/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.7622e-04 - val_loss: 3.8764e-04\n",
            "Epoch 347/500\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.2404e-04 - val_loss: 3.7120e-04\n",
            "Epoch 348/500\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 5.2143e-04 - val_loss: 5.4914e-04\n",
            "Epoch 349/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.9037e-04 - val_loss: 4.6955e-04\n",
            "Epoch 350/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.4073e-04 - val_loss: 3.8870e-04\n",
            "Epoch 351/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.9533e-04 - val_loss: 3.6713e-04\n",
            "Epoch 352/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.7214e-04 - val_loss: 3.7404e-04\n",
            "Epoch 353/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.9288e-04 - val_loss: 3.6198e-04\n",
            "Epoch 354/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.0619e-04 - val_loss: 3.8001e-04\n",
            "Epoch 355/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.6094e-04 - val_loss: 4.2413e-04\n",
            "Epoch 356/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.4419e-04 - val_loss: 3.5885e-04\n",
            "Epoch 357/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.4558e-04 - val_loss: 5.9012e-04\n",
            "Epoch 358/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.9642e-04 - val_loss: 5.9255e-04\n",
            "Epoch 359/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 7.3434e-04 - val_loss: 3.6417e-04\n",
            "Epoch 360/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.9513e-04 - val_loss: 3.8140e-04\n",
            "Epoch 361/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.8179e-04 - val_loss: 7.5460e-04\n",
            "Epoch 362/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 8.6281e-04 - val_loss: 3.8138e-04\n",
            "Epoch 363/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.9487e-04 - val_loss: 3.8074e-04\n",
            "Epoch 364/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.9215e-04 - val_loss: 3.6110e-04\n",
            "Epoch 365/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.6995e-04 - val_loss: 3.6872e-04\n",
            "Epoch 366/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 8.2953e-04 - val_loss: 4.7457e-04\n",
            "Epoch 367/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.4521e-04 - val_loss: 6.0792e-04\n",
            "Epoch 368/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.3292e-04 - val_loss: 3.5613e-04\n",
            "Epoch 369/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.9345e-04 - val_loss: 3.7912e-04\n",
            "Epoch 370/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.8196e-04 - val_loss: 3.3428e-04\n",
            "Epoch 371/500\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.6753e-04 - val_loss: 3.4736e-04\n",
            "Epoch 372/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.1060e-04 - val_loss: 3.3606e-04\n",
            "Epoch 373/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 6.5714e-04 - val_loss: 5.3853e-04\n",
            "Epoch 374/500\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.7083e-04 - val_loss: 6.4648e-04\n",
            "Epoch 375/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.2053e-04 - val_loss: 3.7768e-04\n",
            "Epoch 376/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 6.4807e-04 - val_loss: 6.3458e-04\n",
            "Epoch 377/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.9117e-04 - val_loss: 7.7102e-04\n",
            "Epoch 378/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.6337e-04 - val_loss: 3.6130e-04\n",
            "Epoch 379/500\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.1780e-04 - val_loss: 4.7990e-04\n",
            "Epoch 380/500\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 4.7864e-04 - val_loss: 3.4380e-04\n",
            "Epoch 381/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.0095e-04 - val_loss: 4.2062e-04\n",
            "Epoch 382/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 7.9446e-04 - val_loss: 3.4629e-04\n",
            "Epoch 383/500\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.7467e-04 - val_loss: 5.4998e-04\n",
            "Epoch 384/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.5984e-04 - val_loss: 4.0219e-04\n",
            "Epoch 385/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.9917e-04 - val_loss: 4.0661e-04\n",
            "Epoch 386/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.1705e-04 - val_loss: 4.0782e-04\n",
            "Epoch 387/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.2881e-04 - val_loss: 3.3713e-04\n",
            "Epoch 388/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.1637e-04 - val_loss: 3.1631e-04\n",
            "Epoch 389/500\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.4807e-04 - val_loss: 3.7692e-04\n",
            "Epoch 390/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.6088e-04 - val_loss: 3.7281e-04\n",
            "Epoch 391/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.1489e-04 - val_loss: 4.3699e-04\n",
            "Epoch 392/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.9461e-04 - val_loss: 5.0981e-04\n",
            "Epoch 393/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.4387e-04 - val_loss: 3.1907e-04\n",
            "Epoch 394/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 6.7739e-04 - val_loss: 7.2160e-04\n",
            "Epoch 395/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.1998e-04 - val_loss: 4.6008e-04\n",
            "Epoch 396/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.1255e-04 - val_loss: 4.1609e-04\n",
            "Epoch 397/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.4645e-04 - val_loss: 3.4390e-04\n",
            "Epoch 398/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 6.8082e-04 - val_loss: 0.0014\n",
            "Epoch 399/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 9.1475e-04 - val_loss: 0.0010\n",
            "Epoch 400/500\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 5.7426e-04\n",
            "Epoch 401/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 8.8867e-04 - val_loss: 5.8332e-04\n",
            "Epoch 402/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.2026e-04 - val_loss: 5.1606e-04\n",
            "Epoch 403/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 4.0252e-04\n",
            "Epoch 404/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 405/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.4466e-04 - val_loss: 0.0022\n",
            "Epoch 406/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 5.2164e-04\n",
            "Epoch 407/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.8861e-04 - val_loss: 6.3576e-04\n",
            "Epoch 408/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.4661e-04 - val_loss: 7.7539e-04\n",
            "Epoch 409/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.3119e-04 - val_loss: 4.4495e-04\n",
            "Epoch 410/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 4.7094e-04\n",
            "Epoch 411/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.1521e-04 - val_loss: 0.0021\n",
            "Epoch 412/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 413/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 3.5572e-04\n",
            "Epoch 414/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.4771e-04 - val_loss: 7.4032e-04\n",
            "Epoch 415/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.7652e-04 - val_loss: 4.2219e-04\n",
            "Epoch 416/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.9301e-04 - val_loss: 3.7787e-04\n",
            "Epoch 417/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.1997e-04 - val_loss: 3.3999e-04\n",
            "Epoch 418/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.8591e-04 - val_loss: 5.0396e-04\n",
            "Epoch 419/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.7739e-04 - val_loss: 3.2009e-04\n",
            "Epoch 420/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.2627e-04 - val_loss: 5.7525e-04\n",
            "Epoch 421/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.6485e-04 - val_loss: 5.1592e-04\n",
            "Epoch 422/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.7388e-04 - val_loss: 2.9153e-04\n",
            "Epoch 423/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2167e-04 - val_loss: 4.3712e-04\n",
            "Epoch 424/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.5554e-04 - val_loss: 2.7619e-04\n",
            "Epoch 425/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.8918e-04 - val_loss: 2.8698e-04\n",
            "Epoch 426/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.9143e-04 - val_loss: 2.7514e-04\n",
            "Epoch 427/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.2263e-04 - val_loss: 3.0299e-04\n",
            "Epoch 428/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.3712e-04 - val_loss: 3.0848e-04\n",
            "Epoch 429/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.0807e-04 - val_loss: 2.7266e-04\n",
            "Epoch 430/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.0200e-04 - val_loss: 2.6780e-04\n",
            "Epoch 431/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.8681e-04 - val_loss: 3.7362e-04\n",
            "Epoch 432/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.2051e-04 - val_loss: 3.3094e-04\n",
            "Epoch 433/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.4586e-04 - val_loss: 2.7851e-04\n",
            "Epoch 434/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.8345e-04 - val_loss: 0.0013\n",
            "Epoch 435/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.2401e-04 - val_loss: 5.1085e-04\n",
            "Epoch 436/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 8.6233e-04 - val_loss: 3.3155e-04\n",
            "Epoch 437/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.2692e-04 - val_loss: 8.1119e-04\n",
            "Epoch 438/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.6432e-04 - val_loss: 5.5778e-04\n",
            "Epoch 439/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 3.7135e-04\n",
            "Epoch 440/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.3510e-04 - val_loss: 6.1767e-04\n",
            "Epoch 441/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.4594e-04 - val_loss: 3.3235e-04\n",
            "Epoch 442/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.4695e-04 - val_loss: 2.8026e-04\n",
            "Epoch 443/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.5865e-04 - val_loss: 2.8030e-04\n",
            "Epoch 444/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.1321e-04 - val_loss: 6.2677e-04\n",
            "Epoch 445/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.8988e-04 - val_loss: 3.1301e-04\n",
            "Epoch 446/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9471e-04 - val_loss: 8.2900e-04\n",
            "Epoch 447/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.0385e-04 - val_loss: 7.6413e-04\n",
            "Epoch 448/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.7186e-04 - val_loss: 2.8071e-04\n",
            "Epoch 449/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.1362e-04 - val_loss: 4.9551e-04\n",
            "Epoch 450/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.5238e-04 - val_loss: 3.8345e-04\n",
            "Epoch 451/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.7875e-04 - val_loss: 2.6759e-04\n",
            "Epoch 452/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.4512e-04 - val_loss: 2.9665e-04\n",
            "Epoch 453/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.8429e-04 - val_loss: 2.6160e-04\n",
            "Epoch 454/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.6817e-04 - val_loss: 2.3917e-04\n",
            "Epoch 455/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4270e-04 - val_loss: 2.3914e-04\n",
            "Epoch 456/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.7346e-04 - val_loss: 2.4845e-04\n",
            "Epoch 457/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.6087e-04 - val_loss: 2.3982e-04\n",
            "Epoch 458/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.0040e-04 - val_loss: 2.3970e-04\n",
            "Epoch 459/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.6498e-04 - val_loss: 2.6941e-04\n",
            "Epoch 460/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.7928e-04 - val_loss: 3.1628e-04\n",
            "Epoch 461/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.7494e-04 - val_loss: 4.4776e-04\n",
            "Epoch 462/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.2145e-04 - val_loss: 6.8452e-04\n",
            "Epoch 463/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.6793e-04 - val_loss: 2.2430e-04\n",
            "Epoch 464/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.4877e-04 - val_loss: 3.9487e-04\n",
            "Epoch 465/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.5182e-04 - val_loss: 2.2327e-04\n",
            "Epoch 466/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.4254e-04 - val_loss: 3.8511e-04\n",
            "Epoch 467/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.6301e-04 - val_loss: 2.7300e-04\n",
            "Epoch 468/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.6148e-04 - val_loss: 2.4620e-04\n",
            "Epoch 469/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.6214e-04 - val_loss: 2.3071e-04\n",
            "Epoch 470/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.3172e-04 - val_loss: 2.4027e-04\n",
            "Epoch 471/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.5369e-04 - val_loss: 2.2486e-04\n",
            "Epoch 472/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.4260e-04 - val_loss: 2.1451e-04\n",
            "Epoch 473/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.2792e-04 - val_loss: 2.0937e-04\n",
            "Epoch 474/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.6964e-04 - val_loss: 2.2850e-04\n",
            "Epoch 475/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.1245e-04 - val_loss: 2.3948e-04\n",
            "Epoch 476/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.5601e-04 - val_loss: 2.1585e-04\n",
            "Epoch 477/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3478e-04 - val_loss: 2.0935e-04\n",
            "Epoch 478/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.1357e-04 - val_loss: 2.0595e-04\n",
            "Epoch 479/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.2261e-04 - val_loss: 1.9921e-04\n",
            "Epoch 480/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.2454e-04 - val_loss: 2.1639e-04\n",
            "Epoch 481/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3206e-04 - val_loss: 2.0215e-04\n",
            "Epoch 482/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4807e-04 - val_loss: 1.9539e-04\n",
            "Epoch 483/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.5403e-04 - val_loss: 3.2064e-04\n",
            "Epoch 484/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.8033e-04 - val_loss: 2.9132e-04\n",
            "Epoch 485/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.9275e-04 - val_loss: 2.9637e-04\n",
            "Epoch 486/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.8378e-04 - val_loss: 2.0223e-04\n",
            "Epoch 487/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.2707e-04 - val_loss: 1.9799e-04\n",
            "Epoch 488/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.2493e-04 - val_loss: 1.9699e-04\n",
            "Epoch 489/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9826e-04 - val_loss: 2.8001e-04\n",
            "Epoch 490/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.9077e-04 - val_loss: 4.3850e-04\n",
            "Epoch 491/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.0104e-04 - val_loss: 2.2663e-04\n",
            "Epoch 492/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.1780e-04 - val_loss: 2.5676e-04\n",
            "Epoch 493/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.9024e-04 - val_loss: 2.7304e-04\n",
            "Epoch 494/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.4388e-04 - val_loss: 4.4048e-04\n",
            "Epoch 495/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.3319e-04 - val_loss: 3.6520e-04\n",
            "Epoch 496/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.9583e-04 - val_loss: 2.6632e-04\n",
            "Epoch 497/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4738e-04 - val_loss: 3.0071e-04\n",
            "Epoch 498/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.4919e-04 - val_loss: 1.9436e-04\n",
            "Epoch 499/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3628e-04 - val_loss: 2.2844e-04\n",
            "Epoch 500/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.4434e-04 - val_loss: 3.0099e-04\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.0099e-04\n",
            "Mean squared error: 0.00030099123250693083\n",
            "mape = 8.724177315655698\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model.save('model.h5')\n",
        "pickle.dump(sc, open('scaler.pkl', 'wb'))\n",
        "pickle.dump(sc_y, open('scaler_y.pkl', 'wb'))\n",
        "\n"
      ],
      "metadata": {
        "id": "5E0_mp4Nhi7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "def SPT_fee(stress=100, N=3):\n",
        "  model1 = keras.models.load_model('model.h5')\n",
        "  scaler_x = pickle.load(open('scaler.pkl', 'rb'))\n",
        "  scaler_y = pickle.load(open('scaler_y.pkl', 'rb'))\n",
        "  x = np.array([stress,N])\n",
        "  x=np.reshape(x,(1,2))\n",
        "  x_scale=scaler_x.transform(x)\n",
        "  y_scale=model1.predict(x_scale)\n",
        "  y_scale=np.reshape(y_scale,(1,1))\n",
        "  y=scaler_y.inverse_transform(y_scale) #state parameter\n",
        "  #calculate for friction angle\n",
        "  fee=34.821-27.512*y\n",
        "  return fee[0,0]\n",
        "print('friction angle =',SPT_fee(stress=363,N=60), 'degree')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWvTOjA0i4TZ",
        "outputId": "09bd9acb-736d-4259-f8fc-51ac3c2e9f01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcbc56be3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step\n",
            "friction angle = 36.749664 degree\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiJNatIPZsOA",
        "outputId": "dc1a2b14-c068-4739-8057-be73f9b675f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread"
      ],
      "metadata": {
        "id": "eWXX9Izzp-jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "worksheet = gc.open('SPT').sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "df=pd.DataFrame.from_records(rows)\n"
      ],
      "metadata": {
        "id": "vWVqn-E_jBbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import keras\n",
        "\n",
        "datax=np.array(df)\n",
        "datax=datax[1:,:]\n",
        "datax=datax.astype(float)\n",
        "datax\n",
        "model1 = keras.models.load_model('model.h5')\n",
        "scaler_x = pickle.load(open('scaler.pkl', 'rb'))\n",
        "scaler_y = pickle.load(open('scaler_y.pkl', 'rb'))\n",
        "x_scale=scaler_x.transform(datax)\n",
        "y_scale=model1.predict(x_scale)\n",
        "y=scaler_y.inverse_transform(y_scale) #state parameter\n",
        "  #calculate for friction angle\n",
        "fee=34.821-27.512*y\n",
        "fee_list = fee.tolist()\n",
        "worksheet.update('C2:C30', fee_list)\n",
        "print(fee)"
      ],
      "metadata": {
        "id": "ZHPGVa9HyEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee4fa48-b7ad-4afe-a697-b635c42e184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 193ms/step\n",
            "[[36.581062]\n",
            " [35.88448 ]\n",
            " [34.168518]\n",
            " [31.173197]\n",
            " [27.692755]\n",
            " [24.166595]\n",
            " [37.445892]\n",
            " [37.263084]\n",
            " [36.883217]\n",
            " [34.83939 ]\n",
            " [29.512749]\n",
            " [25.891731]\n",
            " [37.43396 ]\n",
            " [37.421684]\n",
            " [37.165188]\n",
            " [36.44597 ]\n",
            " [34.96586 ]\n",
            " [30.661648]\n",
            " [37.319214]\n",
            " [37.3343  ]\n",
            " [37.36273 ]\n",
            " [36.88687 ]\n",
            " [35.82845 ]\n",
            " [34.08897 ]\n",
            " [36.981956]\n",
            " [37.015377]\n",
            " [37.038002]\n",
            " [36.49786 ]\n",
            " [35.80023 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxrkzlgVyjpF",
        "outputId": "07da8d23-bc74-4046-a33a-643af4a39ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06397443],\n",
              "       [-0.0386551 ],\n",
              "       [ 0.02371621],\n",
              "       [ 0.13258949],\n",
              "       [ 0.25909582],\n",
              "       [ 0.38726392],\n",
              "       [-0.09540901],\n",
              "       [-0.08876438],\n",
              "       [-0.07495707],\n",
              "       [-0.00066845],\n",
              "       [ 0.19294311],\n",
              "       [ 0.32455903],\n",
              "       [-0.09497527],\n",
              "       [-0.0945291 ],\n",
              "       [-0.08520601],\n",
              "       [-0.05906404],\n",
              "       [-0.00526525],\n",
              "       [ 0.1511832 ],\n",
              "       [-0.09080456],\n",
              "       [-0.09135293],\n",
              "       [-0.09238616],\n",
              "       [-0.0750898 ],\n",
              "       [-0.03661861],\n",
              "       [ 0.02660766],\n",
              "       [-0.07854605],\n",
              "       [-0.07976079],\n",
              "       [-0.08058318],\n",
              "       [-0.06095013],\n",
              "       [-0.03559278]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H_Rq2mFYjIg",
        "outputId": "3bd391f6-aec9-49f7-d3ed-2524a52abb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calcualte fro stress\n",
        "s1=5*6+4*6+8*6+9*5+9*4"
      ],
      "metadata": {
        "id": "T9RB0x3NYp0g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5hS1jEvZosH",
        "outputId": "48932d5f-3414-47b7-ca58-8548f1c35498"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calcualte fro stress\n",
        "s1=5*6+4*6+8*6+9*5+9*7+11*9+9*6"
      ],
      "metadata": {
        "id": "jY9l-0P3aFFk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSH0eehEap6C",
        "outputId": "a0af9bf1-39fc-480a-a5b2-4e6ff678488f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUiNn7HIaqnt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}